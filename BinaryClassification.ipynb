{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical testing in binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neccessary stuff\n",
    "1. Train two or more models.\n",
    "1. Evaluate trained models on one or more test datasets (it's a little bit tricky when you want to make several datasets from one).\n",
    "1. Ask a question you want to answer about this models.\n",
    "1. Choose statistical test equivalent to your question.\n",
    "1. Measure neccessary things for this test.\n",
    "1. Assume some significance level, e.g. $\\alpha = 0.05$. \n",
    "1. Calculate p-value for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from sklearn.metrics import accuracy_score\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two models, one data set, what can I do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The path to store trained models\n",
    "models_dir = './models/'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.mkdir(models_dir)\n",
    "\n",
    "# The path to the directory where the original dataset was uncompressed\n",
    "original_dataset_dir = './Dogs-vs-Cats-1'\n",
    "original_cat_dir = './Dogs-vs-Cats-1/Cat'\n",
    "original_dog_dir = './Dogs-vs-Cats-1/Dog'\n",
    "\n",
    "# The directory where we will store our smaller dataset\n",
    "base_dir = './Dogs-vs-Cats-1/working'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "# Directories for our training, validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "\n",
    "# Directory with training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "if not os.path.exists(train_cats_dir):\n",
    "    os.mkdir(train_cats_dir)\n",
    "\n",
    "# Directory with training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "if not os.path.exists(train_dogs_dir):\n",
    "    os.mkdir(train_dogs_dir)\n",
    "\n",
    "# Directory with validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "if not os.path.exists(validation_cats_dir):\n",
    "    os.mkdir(validation_cats_dir)\n",
    "    \n",
    "# Directory with validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "if not os.path.exists(validation_dogs_dir):\n",
    "    os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# Directory with test cat pictures\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "if not os.path.exists(test_cats_dir):\n",
    "    os.mkdir(test_cats_dir)\n",
    "\n",
    "# Directory with test dog pictures\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "if not os.path.exists(test_dogs_dir):\n",
    "    os.mkdir(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy first 1000 cat images to train_cats_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1001)]\n",
    "for fname in fnames:\n",
    "    if fname == '666.jpg':\n",
    "        continue\n",
    "    src = os.path.join(original_cat_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Copy next 500 cat images to validation_cats_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1001, 1501)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_cat_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 cat images to test_cats_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1501, 2001)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_cat_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy first 1000 dog images to train_dogs_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dog_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to validation_dogs_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dog_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to test_dogs_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dog_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_rows = 150\n",
    "img_cols = 150\n",
    "\n",
    "# data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size, \n",
    "        class_mode='binary')\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size, \n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosiek/Documents/VI_semestr/GiGSN/statistical-significance-ml/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# First model\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 473ms/step - acc: 0.5028 - loss: 0.6946 - val_acc: 0.5010 - val_loss: 0.6925\n",
      "Epoch 2/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 465ms/step - acc: 0.5406 - loss: 0.6914 - val_acc: 0.5220 - val_loss: 0.6869\n",
      "Epoch 3/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - acc: 0.5575 - loss: 0.6885 - val_acc: 0.5690 - val_loss: 0.6763\n",
      "Epoch 4/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 455ms/step - acc: 0.5764 - loss: 0.6805 - val_acc: 0.6270 - val_loss: 0.6659\n",
      "Epoch 5/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 461ms/step - acc: 0.5898 - loss: 0.6742 - val_acc: 0.5860 - val_loss: 0.6650\n",
      "Epoch 6/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 451ms/step - acc: 0.6102 - loss: 0.6653 - val_acc: 0.6640 - val_loss: 0.6384\n",
      "Epoch 7/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - acc: 0.6188 - loss: 0.6545 - val_acc: 0.5980 - val_loss: 0.6553\n",
      "Epoch 8/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - acc: 0.6367 - loss: 0.6392 - val_acc: 0.6880 - val_loss: 0.6157\n",
      "Epoch 9/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 438ms/step - acc: 0.6420 - loss: 0.6380 - val_acc: 0.6150 - val_loss: 0.6398\n",
      "Epoch 10/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 441ms/step - acc: 0.6380 - loss: 0.6340 - val_acc: 0.6420 - val_loss: 0.6215\n",
      "Epoch 11/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - acc: 0.6774 - loss: 0.6021 - val_acc: 0.6850 - val_loss: 0.5993\n",
      "Epoch 12/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 437ms/step - acc: 0.6435 - loss: 0.6222 - val_acc: 0.6460 - val_loss: 0.6087\n",
      "Epoch 13/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 426ms/step - acc: 0.6510 - loss: 0.6238 - val_acc: 0.6920 - val_loss: 0.5825\n",
      "Epoch 14/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 426ms/step - acc: 0.6739 - loss: 0.5883 - val_acc: 0.7280 - val_loss: 0.5525\n",
      "Epoch 15/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 422ms/step - acc: 0.6867 - loss: 0.6063 - val_acc: 0.7150 - val_loss: 0.5530\n",
      "Epoch 16/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 415ms/step - acc: 0.6916 - loss: 0.5793 - val_acc: 0.7100 - val_loss: 0.5615\n",
      "Epoch 17/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 415ms/step - acc: 0.6856 - loss: 0.5935 - val_acc: 0.7200 - val_loss: 0.5458\n",
      "Epoch 18/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 418ms/step - acc: 0.7060 - loss: 0.5639 - val_acc: 0.7340 - val_loss: 0.5571\n",
      "Epoch 19/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 434ms/step - acc: 0.7062 - loss: 0.5753 - val_acc: 0.7290 - val_loss: 0.5383\n",
      "Epoch 20/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 434ms/step - acc: 0.7190 - loss: 0.5599 - val_acc: 0.7100 - val_loss: 0.5494\n",
      "Epoch 21/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 444ms/step - acc: 0.7078 - loss: 0.5764 - val_acc: 0.7290 - val_loss: 0.5281\n",
      "Epoch 22/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 431ms/step - acc: 0.7426 - loss: 0.5362 - val_acc: 0.7390 - val_loss: 0.5457\n",
      "Epoch 23/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 432ms/step - acc: 0.7278 - loss: 0.5485 - val_acc: 0.7160 - val_loss: 0.5457\n",
      "Epoch 24/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 457ms/step - acc: 0.7278 - loss: 0.5487 - val_acc: 0.7340 - val_loss: 0.5710\n",
      "Epoch 25/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 421ms/step - acc: 0.7332 - loss: 0.5386 - val_acc: 0.7250 - val_loss: 0.5325\n",
      "Epoch 26/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 430ms/step - acc: 0.7351 - loss: 0.5482 - val_acc: 0.7440 - val_loss: 0.5237\n",
      "Epoch 27/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 468ms/step - acc: 0.7434 - loss: 0.5231 - val_acc: 0.7620 - val_loss: 0.4923\n",
      "Epoch 28/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 468ms/step - acc: 0.7507 - loss: 0.5293 - val_acc: 0.7520 - val_loss: 0.4925\n",
      "Epoch 29/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 470ms/step - acc: 0.7242 - loss: 0.5446 - val_acc: 0.7620 - val_loss: 0.4927\n",
      "Epoch 30/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - acc: 0.7367 - loss: 0.5317 - val_acc: 0.7550 - val_loss: 0.5065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe858359060>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=3e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model1.fit(\n",
    "      train_generator,\n",
    "      batch_size=batch_size,\n",
    "      epochs=30,\n",
    "      validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model1.save(models_dir+\"binary_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosiek/Documents/VI_semestr/GiGSN/statistical-significance-ml/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-06-04 17:58:47.745390: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 17:58:47.745619: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 17:58:47.745806: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 17:58:47.840001: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 17:58:47.840211: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 17:58:47.840369: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 17:58:47.840506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2739 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Second model\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(512, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosiek/Documents/VI_semestr/GiGSN/statistical-significance-ml/.venv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717516750.160268   20110 service.cc:145] XLA service 0x7b60a4005120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1717516750.160312   20110 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti, Compute Capability 7.5\n",
      "2024-06-04 17:59:10.239191: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-04 17:59:10.543940: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:33\u001b[0m 10s/step - acc: 0.6562 - loss: 0.6889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717516757.767481   20110 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 252ms/step - acc: 0.5286 - loss: 0.6947 - val_acc: 0.5000 - val_loss: 0.6943\n",
      "Epoch 2/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 129ms/step - acc: 0.4966 - loss: 0.6931 - val_acc: 0.5150 - val_loss: 0.6912\n",
      "Epoch 3/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step - acc: 0.5422 - loss: 0.6908 - val_acc: 0.5040 - val_loss: 0.6872\n",
      "Epoch 4/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 134ms/step - acc: 0.5752 - loss: 0.6818 - val_acc: 0.5590 - val_loss: 0.6643\n",
      "Epoch 5/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - acc: 0.6185 - loss: 0.6555 - val_acc: 0.6460 - val_loss: 0.6345\n",
      "Epoch 6/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 139ms/step - acc: 0.6139 - loss: 0.6446 - val_acc: 0.6630 - val_loss: 0.6288\n",
      "Epoch 7/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - acc: 0.6536 - loss: 0.6255 - val_acc: 0.6970 - val_loss: 0.6040\n",
      "Epoch 8/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 144ms/step - acc: 0.6776 - loss: 0.6084 - val_acc: 0.6900 - val_loss: 0.6023\n",
      "Epoch 9/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - acc: 0.6596 - loss: 0.6102 - val_acc: 0.7250 - val_loss: 0.5678\n",
      "Epoch 10/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - acc: 0.6796 - loss: 0.6062 - val_acc: 0.6810 - val_loss: 0.6006\n",
      "Epoch 11/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - acc: 0.6821 - loss: 0.5857 - val_acc: 0.7220 - val_loss: 0.5790\n",
      "Epoch 12/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 134ms/step - acc: 0.6940 - loss: 0.5784 - val_acc: 0.6960 - val_loss: 0.5647\n",
      "Epoch 13/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - acc: 0.6848 - loss: 0.5814 - val_acc: 0.7330 - val_loss: 0.5361\n",
      "Epoch 14/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 135ms/step - acc: 0.7269 - loss: 0.5471 - val_acc: 0.7160 - val_loss: 0.5514\n",
      "Epoch 15/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - acc: 0.7240 - loss: 0.5404 - val_acc: 0.7450 - val_loss: 0.5188\n",
      "Epoch 16/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - acc: 0.7173 - loss: 0.5510 - val_acc: 0.7290 - val_loss: 0.5469\n",
      "Epoch 17/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 140ms/step - acc: 0.7344 - loss: 0.5535 - val_acc: 0.6750 - val_loss: 0.5748\n",
      "Epoch 18/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step - acc: 0.7145 - loss: 0.5594 - val_acc: 0.7600 - val_loss: 0.4968\n",
      "Epoch 19/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 140ms/step - acc: 0.7583 - loss: 0.5134 - val_acc: 0.7420 - val_loss: 0.5343\n",
      "Epoch 20/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - acc: 0.7269 - loss: 0.5249 - val_acc: 0.7060 - val_loss: 0.5672\n",
      "Epoch 21/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - acc: 0.7475 - loss: 0.5296 - val_acc: 0.7640 - val_loss: 0.4875\n",
      "Epoch 22/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 136ms/step - acc: 0.7507 - loss: 0.4958 - val_acc: 0.7590 - val_loss: 0.4847\n",
      "Epoch 23/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 135ms/step - acc: 0.7578 - loss: 0.5131 - val_acc: 0.7190 - val_loss: 0.5552\n",
      "Epoch 24/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - acc: 0.7479 - loss: 0.5192 - val_acc: 0.7720 - val_loss: 0.4831\n",
      "Epoch 25/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 140ms/step - acc: 0.7727 - loss: 0.4870 - val_acc: 0.7540 - val_loss: 0.4917\n",
      "Epoch 26/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 138ms/step - acc: 0.7613 - loss: 0.4923 - val_acc: 0.7860 - val_loss: 0.4581\n",
      "Epoch 27/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 135ms/step - acc: 0.7592 - loss: 0.4897 - val_acc: 0.7890 - val_loss: 0.4696\n",
      "Epoch 28/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - acc: 0.7645 - loss: 0.4970 - val_acc: 0.7670 - val_loss: 0.4779\n",
      "Epoch 29/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - acc: 0.7685 - loss: 0.4826 - val_acc: 0.7770 - val_loss: 0.4625\n",
      "Epoch 30/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - acc: 0.7839 - loss: 0.4641 - val_acc: 0.7850 - val_loss: 0.4394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b61ee3a7a00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=3e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model2.fit(\n",
    "      train_generator,\n",
    "      batch_size=batch_size,\n",
    "      epochs=30,\n",
    "      validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model2.save(models_dir+\"binary_model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want to know if one model is better than other?\n",
    "Perform McNemar's test! It's simple statistic based on *False Negatives* clasified only one of the two models. The statistic of this test is calucated by equation below:\n",
    "$$\\chi^2 = \\frac{(|b-c|-1)^2}{b+c}$$\n",
    "* b - *False Negatives* clasified by first model, but not by the second,\n",
    "* c - *False Negatives* clasified by second model, but not the first.\n",
    "\n",
    "This test follows chi-squared distribution with one degree of freedom when $b+c\\geq20$, and binomial distribution in the other case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model1 = load_model(models_dir+\"binary_model1.h5\")\n",
    "model2 = load_model(models_dir+\"binary_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict \n",
    "y_true = test_generator.labels\n",
    "size = len(y_true)\n",
    "y_pred1 = np.array([model1.predict(test_generator) > 0.5], dtype=int).reshape((size,))\n",
    "y_pred2 = np.array([model2.predict(test_generator) > 0.5], dtype=int).reshape((size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives classified by first model, but not by the second: 52\n",
      "False negatives classified by second model, but not by the first: 19\n"
     ]
    }
   ],
   "source": [
    "# Calculate b and c\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(size):\n",
    "    if y_true[i] == 1:\n",
    "        if y_pred1[i] == 0 and y_pred2[i] == 1:\n",
    "            b += 1\n",
    "        elif y_pred1[i] == 1 and y_pred2[i] == 0:\n",
    "            c += 1 \n",
    "\n",
    "print(\"False negatives classified by first model, but not by the second:\", b)\n",
    "print(\"False negatives classified by second model, but not by the first:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00029208831796774206\n"
     ]
    }
   ],
   "source": [
    "# Calulate test statistic\n",
    "chi2 = (abs(b-c) - 1)**2/(b+c)\n",
    "p = 2 * scipy.stats.chi2.sf(chi2, 1)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
