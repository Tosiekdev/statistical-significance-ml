{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical testing in binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neccessary stuff\n",
    "1. Train two or more models.\n",
    "1. Evaluate trained models on one or more test datasets (it's a little bit tricky when you want to make several datasets from one).\n",
    "1. Ask a question you want to answer about this models.\n",
    "1. Choose statistical test equivalent to your question.\n",
    "1. Measure neccessary things for this test.\n",
    "1. Assume some significance level, e.g. $\\alpha = 0.5$. \n",
    "1. Calculate p-value for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 22:03:20.965012: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 22:03:21.909375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two models, one data set, what can I do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The path to store trained models\n",
    "models_dir = './models/'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.mkdir(models_dir)\n",
    "\n",
    "# The path to the directory where the original dataset was uncompressed\n",
    "original_dataset_dir = './Dogs-vs-Cats-1'\n",
    "original_cat_dir = './Dogs-vs-Cats-1/Cat'\n",
    "original_dog_dir = './Dogs-vs-Cats-1/Dog'\n",
    "\n",
    "# The directory where we will store our smaller dataset\n",
    "base_dir = './Dogs-vs-Cats-1/working'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "# Directories for our training, validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "\n",
    "# Directory with training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "if not os.path.exists(train_cats_dir):\n",
    "    os.mkdir(train_cats_dir)\n",
    "\n",
    "# Directory with training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "if not os.path.exists(train_dogs_dir):\n",
    "    os.mkdir(train_dogs_dir)\n",
    "\n",
    "# Directory with validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "if not os.path.exists(validation_cats_dir):\n",
    "    os.mkdir(validation_cats_dir)\n",
    "    \n",
    "# Directory with validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "if not os.path.exists(validation_dogs_dir):\n",
    "    os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# Directory with test cat pictures\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "if not os.path.exists(test_cats_dir):\n",
    "    os.mkdir(test_cats_dir)\n",
    "\n",
    "# Directory with test dog pictures\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "if not os.path.exists(test_dogs_dir):\n",
    "    os.mkdir(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy first 1000 cat images to train_cats_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1001)]\n",
    "for fname in fnames:\n",
    "    if fname == '666.jpg':\n",
    "        continue\n",
    "    src = os.path.join(original_cat_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Copy next 500 cat images to validation_cats_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1001, 1501)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_cat_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 cat images to test_cats_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1501, 2001)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_cat_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy first 1000 dog images to train_dogs_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dog_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to validation_dogs_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dog_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to test_dogs_dir\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dog_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_rows = 150\n",
    "img_cols = 150\n",
    "\n",
    "# data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size, \n",
    "        class_mode='binary')\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size, \n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosiek/Documents/VI_semestr/GiGSN/statistical-significance-ml/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# First model\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 473ms/step - acc: 0.5028 - loss: 0.6946 - val_acc: 0.5010 - val_loss: 0.6925\n",
      "Epoch 2/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 465ms/step - acc: 0.5406 - loss: 0.6914 - val_acc: 0.5220 - val_loss: 0.6869\n",
      "Epoch 3/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - acc: 0.5575 - loss: 0.6885 - val_acc: 0.5690 - val_loss: 0.6763\n",
      "Epoch 4/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 455ms/step - acc: 0.5764 - loss: 0.6805 - val_acc: 0.6270 - val_loss: 0.6659\n",
      "Epoch 5/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 461ms/step - acc: 0.5898 - loss: 0.6742 - val_acc: 0.5860 - val_loss: 0.6650\n",
      "Epoch 6/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 451ms/step - acc: 0.6102 - loss: 0.6653 - val_acc: 0.6640 - val_loss: 0.6384\n",
      "Epoch 7/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - acc: 0.6188 - loss: 0.6545 - val_acc: 0.5980 - val_loss: 0.6553\n",
      "Epoch 8/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - acc: 0.6367 - loss: 0.6392 - val_acc: 0.6880 - val_loss: 0.6157\n",
      "Epoch 9/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 438ms/step - acc: 0.6420 - loss: 0.6380 - val_acc: 0.6150 - val_loss: 0.6398\n",
      "Epoch 10/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 441ms/step - acc: 0.6380 - loss: 0.6340 - val_acc: 0.6420 - val_loss: 0.6215\n",
      "Epoch 11/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - acc: 0.6774 - loss: 0.6021 - val_acc: 0.6850 - val_loss: 0.5993\n",
      "Epoch 12/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 437ms/step - acc: 0.6435 - loss: 0.6222 - val_acc: 0.6460 - val_loss: 0.6087\n",
      "Epoch 13/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 426ms/step - acc: 0.6510 - loss: 0.6238 - val_acc: 0.6920 - val_loss: 0.5825\n",
      "Epoch 14/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 426ms/step - acc: 0.6739 - loss: 0.5883 - val_acc: 0.7280 - val_loss: 0.5525\n",
      "Epoch 15/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 422ms/step - acc: 0.6867 - loss: 0.6063 - val_acc: 0.7150 - val_loss: 0.5530\n",
      "Epoch 16/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 415ms/step - acc: 0.6916 - loss: 0.5793 - val_acc: 0.7100 - val_loss: 0.5615\n",
      "Epoch 17/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 415ms/step - acc: 0.6856 - loss: 0.5935 - val_acc: 0.7200 - val_loss: 0.5458\n",
      "Epoch 18/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 418ms/step - acc: 0.7060 - loss: 0.5639 - val_acc: 0.7340 - val_loss: 0.5571\n",
      "Epoch 19/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 434ms/step - acc: 0.7062 - loss: 0.5753 - val_acc: 0.7290 - val_loss: 0.5383\n",
      "Epoch 20/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 434ms/step - acc: 0.7190 - loss: 0.5599 - val_acc: 0.7100 - val_loss: 0.5494\n",
      "Epoch 21/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 444ms/step - acc: 0.7078 - loss: 0.5764 - val_acc: 0.7290 - val_loss: 0.5281\n",
      "Epoch 22/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 431ms/step - acc: 0.7426 - loss: 0.5362 - val_acc: 0.7390 - val_loss: 0.5457\n",
      "Epoch 23/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 432ms/step - acc: 0.7278 - loss: 0.5485 - val_acc: 0.7160 - val_loss: 0.5457\n",
      "Epoch 24/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 457ms/step - acc: 0.7278 - loss: 0.5487 - val_acc: 0.7340 - val_loss: 0.5710\n",
      "Epoch 25/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 421ms/step - acc: 0.7332 - loss: 0.5386 - val_acc: 0.7250 - val_loss: 0.5325\n",
      "Epoch 26/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 430ms/step - acc: 0.7351 - loss: 0.5482 - val_acc: 0.7440 - val_loss: 0.5237\n",
      "Epoch 27/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 468ms/step - acc: 0.7434 - loss: 0.5231 - val_acc: 0.7620 - val_loss: 0.4923\n",
      "Epoch 28/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 468ms/step - acc: 0.7507 - loss: 0.5293 - val_acc: 0.7520 - val_loss: 0.4925\n",
      "Epoch 29/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 470ms/step - acc: 0.7242 - loss: 0.5446 - val_acc: 0.7620 - val_loss: 0.4927\n",
      "Epoch 30/30\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - acc: 0.7367 - loss: 0.5317 - val_acc: 0.7550 - val_loss: 0.5065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe858359060>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=3e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model1.fit(\n",
    "      train_generator,\n",
    "      batch_size=batch_size,\n",
    "      epochs=30,\n",
    "      validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model1.save(models_dir+\"binary_model1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want to know if one model is better than other?\n",
    "Perform McNemar's test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
